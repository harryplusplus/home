---
title: "Withsy"
pubDate: 2025-05-19
description: "Withsy is a user-centric AI chat application that empowers you to tailor your conversational experience. It provides robust features for managing prompts, customizing interactions, and securely saving your valuable chats and messages."
---

import Mermaid from "@/components/Mermaid.astro";

# {frontmatter.title}

## Table of Contents

## What Is Withsy?

{frontmatter.description}

Try it through the [link](https://withsy.chat/).

## Why We Created This?

Withsy는 저와 [Jenn](https://www.hellojennpark.com/) 두 명의 소프트웨어 엔지니어가 만들었습니다.
범람하는 AI 챗앱 시대지만 우리의 사용사례를 위한 AI 챗앱이 없었습니다.
예를 들어, 질문에 대한 Google Gemini의 대답이 마음에 들지 않아서 xAI Grok에게 물어보고 싶을 경우, 대화 뿐만 아니라 대화의 컨텍스트를 전달해야하는데 이 과정은 불편하고 지루합니다.
그래서 하나의 챗앱에서 여러 AI에게 대화의 컨텍스트를 전달하거나 대화를 분기할 수 있는 기능을 만들었습니다.
그리고 특정 질문이나 대답을 추후 확인하거나 재확인하기 위해 즐겨찾기하고 해당 컨텍스트로 바로 이동할 수 있는 기능이 없었습니다.
그래서 Withsy를 만들었습니다.

## Architecture

<Mermaid chart={`
architecture-beta

group withsy(withsy:logo)[Withsy]

service db(aws:arch-amazon-rds-64)[Amazon RDS for Postgres] in withsy
service storage(supabase:supabase-logo-icon)[Supabase Storage] in withsy
service server(google-cloud:cloud-run)[Google Cloud Run] in withsy

server:R -- L:db
server:B -- T:storage
`}/>

### Why Use Google Cloud Run?

Google Cloud Run은 도커 컨테이너 기반의 무중단 배포와 자동 스케일 아웃을 제공합니다.

이는 저희 서비스의 요구사항과 잘 맞다고 생각합니다.
저희 서비스는 AI 채팅 웹앱입니다. 그리고 SSE를 사용해서 AI 응답을 스트리밍합니다.
그래서 클라우드 서비스의 HTTP 요청 타임아웃 제한이 치명적으로 작용할 수 있습니다.
AWS Lambda 또는 App Runner는 최대 15분의 요청 타임아웃 제한을 갖습니다.
이는 AI 채팅 웹앱의 요구사항에 대해서 구현의 제약사항으로 작용합니다.
반면에 Google Cloud Run 또는 Google Cloud Run Functions는 최대 60분의 요청 타임아웃 제한을 갖습니다.
이는 구현의 제약사항으로 작용하지 않는다고 생각했습니다.

쿠버네티스 기반의 클라우드 서비스는 사용하고 싶지 않았습니다.
왜냐하면 소규모 팀 입장에서 쿠버네티스의 운영은 시간 및 정신 비용으로 이어진다고 생각했기 때문입니다.
그래서 쿠버네티스를 사용하지 않으면서도 무중단 배포 및 자동 스케일 아웃을 제공하는 관리형 서비스인 Google Cloud Run 또는 AWS App Runner를 후보로 생각했었습니다.

그리고 저는 가능한한 프로덕션과 개발 환경의 일치를 추구합니다.
왜냐하면 환경의 불일치는 종종 예기치않은 오류로 이어지기 때문입니다.
TODO 그래서 도커 컨테이너 ...


클라우드 서비스 환경은 크게 3가지의 타입이 있습니다.
VM, 도커 컨테이너 또는 서버리스 환경입니다.
서버리스는 연결을 유지할 수 없거나 유지하는 

Google Cloud Run은 저희의 모놀리스 서버를 배포하고 운영하는데 필요한 조건을 갖추고 있습니다.
첫 번째로, 관리형 서비스입니다.
소규모 개발 및 운영하는 작은 서비스이기 때문에 쿠버네티스와 같은 인프라 관리 및 운영을 위한 시간적 정신적 비용을 지불하고 싶지 않았습니다.
Google Cloud Run은 자동 스케일 아웃과 무중단 배포가 가능합니다.
두 번째로, 서버리스가 아닌 서버 기반의 서비스입니다.
위와 마찬가지로 소규모 개발 및 운영해야하기 때문에, 개발과 프로덕션 환경의 일치가 중요하다고 생각했습니다.
개발시 Node.js 서버 환경에서 개발을 하고, 프로덕션에서도 같은 Node.js 서버 환경이어야 운영이 예측 가능하기 때문입니다.
서버리스 함수의 경우 개발 환경인 Node.js와 다르고 CPU, 메모리 그리고 실행 시간의 제약도 있기 때문에, 개발 중 알 수 없는 오류가 프로덕션에서 발생할 수 있다고 생각합니다.
특히 AI 응답 스트리밍 설계 및 초기 개발 단계에서 이런 이른 최적화 비용을 지불하고 싶지 않았습니다.

#### Why Use Monolith?

먼저 우리는 이 웹앱을 구축하기 위해서 Next.js 프레임워크를 선택했습니다.
Jenn이 현업에서 다년간 Next.js를 사용했고, 좋은 결과물을 만들었었기 때문입니다.
그리고 저는 Next.js가 프로덕션에서 많이 사용될만큼 안정적인 생태계를 갖고 있다고 생각했습니다.
하지만 저는 요즘 Node.js 웹앱 개발 아키텍처인 프론트엔드를 위한 백엔드와 백엔드를 위한 백엔드 아키텍처를 피하고 싶었습니다.
왜냐하면 개발시 두 개의 서버를 띄워야 하고, 공통 모듈을 별도의 패키지로 분리해야 하기 때문에 모노리포를 도입해야 하기 때문입니다.
이 기술들은 마이크로 서비스 아키텍처 개발 패턴입니다.

소규모 개발 및 운영시 마이크로 서비스 아키텍처와 관련된 기술 패턴은 불필요하다고 생각했습니다.
서비스 아키텍처는 조직의 아키텍처의 반영이라고 생각합니다.
조직의 규모가 크고 서비스가 명확히 분리되는 경우에 마이크로 서비스 아키텍처가 유효하다고 생각합니다.
마이크로 서비스 아키텍처는 세부 조직간 최소한의 인터페이스만 유지해 세부 조직의 자율성을 존중하고 세부 조직간 의존성을 줄여 큰 퍼포먼스를 만들기 좋은 구조라고 생각합니다.
반면에 풀스택 소프트웨어 엔지니어 두 명으로 이뤄진 저희 조직에서 마이크로 서비스 아키텍처와 관련 기술을 사용하는 것은 불필요한 인터페이스 생성과 그것을 보강하기 위한 추가적인 오버헤드만 생성한다고 생각합니다.

그래서 HTML 렌더링을 위한 프론트엔드, HTTP API를 위한 백엔드 그리고 백그라운드 워커를 하나의 Node.js 런타임 위의 Next.js 프레임워크 내에서 처리했습니다.

### Why Use Amazon RDS for Postgres?

TODO

### Why Use Supabase Storage?

TODO
